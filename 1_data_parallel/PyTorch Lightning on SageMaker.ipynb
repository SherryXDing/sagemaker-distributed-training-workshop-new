{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8552dfc1-b335-416c-a92a-47ca4a3d920d",
   "metadata": {},
   "source": [
    "# Data Parallel on Amazon SageMaker Training with PyTorch Lightning\n",
    "In this lab we'll write our own deep neural network using PyTorch Lightning, and train this on Amazon SageMaker. For more details [see our blog post here.](https://aws.amazon.com/blogs/machine-learning/run-pytorch-lightning-and-native-pytorch-ddp-on-amazon-sagemaker-training-featuring-amazon-search/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f6c4ea-5f6d-439f-8690-202b0a26d374",
   "metadata": {},
   "source": [
    "### Step 0. Update the SageMaker Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562030f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade sagemaker\n",
    "%pip install boto3 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8be361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "# make sure this is at least 2.102.0\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6667f8be-05fa-4ce3-9fac-13d811338196",
   "metadata": {},
   "source": [
    "### Step 1. Write train script and requirements into a local directory, here named `scripts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6bb6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scripts/requirements.txt\n",
    "pytorch-lightning == 1.6.3\n",
    "lightning-bolts == 0.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb91c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scripts/mnist.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.strategies import DDPStrategy\n",
    "\n",
    "from pytorch_lightning.plugins.environments.lightning_environment import LightningEnvironment\n",
    "from pl_bolts.datamodules.mnist_datamodule import MNISTDataModule\n",
    "\n",
    "import argparse\n",
    "\n",
    "class LitClassifier(pl.LightningModule):\n",
    "    def __init__(self, hidden_dim: int = 128, learning_rate: float = 0.0001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.l1 = torch.nn.Linear(28 * 28, self.hparams.hidden_dim)\n",
    "        self.l2 = torch.nn.Linear(self.hparams.hidden_dim, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.l1(x))\n",
    "        x = torch.relu(self.l2(x))\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        probs = self(x)\n",
    "        # we currently return the accuracy as the validation_step/test_step is run on the IPU devices.\n",
    "        # Outputs from the step functions are sent to the host device, where we calculate the metrics in\n",
    "        # validation_epoch_end and test_epoch_end for the test_step.\n",
    "        acc = self.accuracy(probs, y)\n",
    "        return acc\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        acc = self.accuracy(logits, y)\n",
    "        return acc\n",
    "\n",
    "    def accuracy(self, logits, y):\n",
    "        # currently IPU poptorch doesn't implicit convert bools to tensor\n",
    "        # hence we use an explicit calculation for accuracy here. Once fixed in poptorch\n",
    "        # we can use the accuracy metric.\n",
    "        acc = torch.sum(torch.eq(torch.argmax(logits, -1), y).to(torch.float32)) / len(y)\n",
    "        return acc\n",
    "\n",
    "    def validation_epoch_end(self, outputs) -> None:\n",
    "        # since the training step/validation step and test step are run on the IPU device\n",
    "        # we must log the average loss outside the step functions.\n",
    "        self.log(\"val_acc\", torch.stack(outputs).mean(), prog_bar=True)\n",
    "\n",
    "    def test_epoch_end(self, outputs) -> None:\n",
    "        self.log(\"test_acc\", torch.stack(outputs).mean())\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "    \n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--hosts\", type=list, default=os.environ[\"SM_HOSTS\"])\n",
    "    parser.add_argument(\"--current-host\", type=str, default=os.environ[\"SM_CURRENT_HOST\"])\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ[\"SM_MODEL_DIR\"])\n",
    "    parser.add_argument(\"--num-gpus\", type=int, default=int(os.environ[\"SM_NUM_GPUS\"]))\n",
    "\n",
    "    parser.add_argument(\"--num_nodes\", type=int, default = len(os.environ[\"SM_HOSTS\"]))\n",
    "           \n",
    "    # num gpus is per node\n",
    "    world_size = int(os.environ[\"SM_NUM_GPUS\"]) * len(os.environ[\"SM_HOSTS\"])\n",
    "                 \n",
    "    parser.add_argument(\"--world-size\", type=int, default=world_size)\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    return args\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    args = parse_args()\n",
    "    \n",
    "    dm = MNISTDataModule(batch_size=32)\n",
    "    \n",
    "    model = LitClassifier()\n",
    "    \n",
    "    local_rank = os.environ[\"LOCAL_RANK\"]\n",
    "    torch.cuda.set_device(int(local_rank))\n",
    "    \n",
    "    num_nodes = args.num_nodes\n",
    "    num_gpus = args.num_gpus\n",
    "    \n",
    "    env = LightningEnvironment()\n",
    "    \n",
    "    env.world_size = lambda: int(os.environ.get(\"WORLD_SIZE\", 0))\n",
    "    env.global_rank = lambda: int(os.environ.get(\"RANK\", 0))\n",
    "    \n",
    "    ddp = DDPStrategy(cluster_environment=env, accelerator=\"gpu\")\n",
    "    \n",
    "    trainer = pl.Trainer(max_epochs=200, strategy=ddp, devices=num_gpus, num_nodes=num_nodes, default_root_dir = args.model_dir)\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "    trainer.test(model, datamodule=dm)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0081599c-4683-4080-90db-4ef6f07cdf13",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2. Configure the SageMaker Training api locally \n",
    "In this step you are using the [SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) as a wrapper around the core api, `create-training-job`, [as described here.](https://docs.aws.amazon.com/cli/latest/reference/sagemaker/create-training-job.html)\n",
    "\n",
    "Read more about [training on SageMaker here,](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html) with distributed training details [here.](https://docs.aws.amazon.com/sagemaker/latest/dg/distributed-training.html)\n",
    "\n",
    "\n",
    "You can see [instance details for SageMaker here,](https://aws.amazon.com/sagemaker/pricing/) along with [instance specs from EC2 directly here.](https://aws.amazon.com/ec2/instance-types/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f475a5a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.local import LocalSession\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "# hard code point to the DLC images\n",
    "image_uri = '763104351884.dkr.ecr.{}.amazonaws.com/pytorch-training:1.12.0-gpu-py38-cu113-ubuntu20.04-sagemaker'.format(region)\n",
    "\n",
    "estimator = PyTorch(\n",
    "  entry_point=\"mnist.py\",\n",
    "  base_job_name=\"lightning-ddp-mnist\",\n",
    "  image_uri = image_uri,\n",
    "  role=role,\n",
    "  source_dir=\"scripts\",\n",
    "  # configures the SageMaker training resource, you can increase as you need\n",
    "  instance_count=1,\n",
    "  instance_type=\"ml.g4dn.12xlarge\",\n",
    "  py_version=\"py38\",\n",
    "  sagemaker_session=sagemaker_session,\n",
    "  distribution={\"pytorchddp\":{\"enabled\": True}},\n",
    "  debugger_hook_config=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e19902f-5fe4-438d-972c-5348dacf1f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing True will halt your kernel, passing False will not. both create a training job.\n",
    "estimator.fit(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8302f5ce-93b9-45c7-9217-70af6f4becce",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3. Download a profiler report\n",
    "Unless disabled, SageMaker will generate a report to analyze your overall job metrics and provide helpful insights that you can use to increase performance. Details on the report, including how to access it, [are provided here.](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-profiling-report.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543f2d79-f3af-4442-a3a7-f38309fb1dbd",
   "metadata": {},
   "source": [
    "If you need to restart your kernel, you can re-establish the estimator variable here.\n",
    "`estimator = PyTorch.attach(\"your_training_job_name\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a76ebb-3a87-4722-89d8-b698674499a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "job_name = 'lightning-ddp-mnist-2022-08-23-02-11-37-450'\n",
    "estimator = PyTorch.attach(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc815388-596e-437d-8895-01fe2727482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# point to an S3 path using your estimator variable\n",
    "rule_output_path = estimator.output_path + estimator.latest_training_job.job_name + \"/rule-output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187b6744-bac0-4b1a-a24d-a5b74609baba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use the AWS CLI to copy the report locally\n",
    "! aws s3 cp {rule_output_path} ./ --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd532a59-9888-4bb9-92be-1feb276be8d0",
   "metadata": {},
   "source": [
    "### Step 4. Optimize!\n",
    "That's the end of this lab. However, in the real world, this is just the begining. Here are a few extra things you can do to increase model accuracy (hopefully) and decrease job runtime (certainly).\n",
    "1. **Increase throughput by adding extra nodes.** Increase the number of instances in `instance_count`, and as long as you're using some for of distribution in your training script, this will automatically copy your model over all available accelerators and handle averaging the results. This is also called ***horizontal scaling.***\n",
    "2. **Increase throughput by upgrading your instances.** In addition to (or sometimes instead of) adding extra nodes, you can increase your instance to something larger. This usually means adding more accelerators, more CPU, more memory, and more bandwidth. \n",
    "3. **Increase accuracy with hyperparameter tuning**. Another critical step is picking the right hyperparameters. You can use [Syne Tune](https://github.com/awslabs/syne-tune/blob/hf_blog_post/hf_blog_post/example_syne_tune_for_hf.ipynb) for a multi-objective tuning metric as one example. Here's another example with [SageMaker Training Compiler to tune the batch size!](https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-training-compiler/huggingface/pytorch_tune_batch_size/finding_max_batch_size_for_model_training.ipynb)\n",
    "4. **Increase accuracy by adding more parameters to your model, and using a model parallel strategy.** This is the content of the next lab!"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.10-cpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
