{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f671ae67-f9fe-4f36-a40c-4911a50504d8",
   "metadata": {},
   "source": [
    "# Stable Diffusion with Distributed Training and Hosting on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443c5040-dfde-4a3f-ab62-91d107b28c5c",
   "metadata": {},
   "source": [
    "In this notebook, you will learn how you can fine-tune a pretrained [Stable Diffusion](https://stability.ai/blog/stable-diffusion-public-release) model on SageMaker and deploy it for inference.\n",
    "\n",
    "Produced by Stability.ai, Stable Diffusion is an open source model available for researchers and the broader ML community. We're pointing to the core content available on Hugging Face [here](https://huggingface.co/CompVis/stable-diffusion-v1-4) and provide private access in the limited context of hands-on workshops. If you'd like longer term access to Stable Diffusion, you'll need to sign up on the Hugging Face Hub, accept the terms, create a token, and download the model and dataset. \n",
    "\n",
    "In this lab, we've done that for you already. So let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75580a08-54ce-4f55-a7ea-b34eaf1d6fc9",
   "metadata": {},
   "source": [
    "This notebook is purely educational for showing how to fine-tune latent-stable-diffusion on Amazon SageMaker. Neither the images produced or code represent Amazon or its views in any way shape or form. To properly leverage this codebase, read the corresponding licenses from [CompVis](https://huggingface.co/spaces/CompVis/stable-diffusion-license) (the model) and [Conceptual Captions](https://huggingface.co/datasets/conceptual_captions) (from Google, but you will use HF)\n",
    "\n",
    "Model weights were provided by CompVis/stable-diffusion-v1-4. You can find the licensing, README and more [here](https://huggingface.co/CompVis/stable-diffusion-v1-4).  Please note that the finetune.py script has been slightly modified from a PR request [here](https://github.com/huggingface/diffusers/pull/356)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f870350f-5d95-4dba-a008-6ed946b18ac1",
   "metadata": {},
   "source": [
    "### Step 1. Point to the model and data in S3\n",
    "\n",
    "First, ask the instructor for the name of the S3 bucket you need to point to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f446849-ea83-4d8a-822d-b75f54cc63ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"< BUCKET NAME HERE>\" \n",
    "path = \"stable-diffusion/conceptual_captions\"\n",
    "s3_train_channel = f\"s3://{bucket}/{path}\"\n",
    "image_file = '0.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14188fb-2e5d-4ac1-aa13-d452a78e0370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp {s3_train_channel}/{image} .\n",
    "!aws s3 cp {s3_train_channel}/dataset.parquet ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc4db69-8b8c-4520-a623-02ef6287ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4862f17-4f0a-4b2d-af8e-1ab628eb9d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64398d0a-d96c-49e3-aed0-222f3ad4bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption = df['caption'][0]\n",
    "from PIL import Image\n",
    "\n",
    "print (caption)\n",
    "\n",
    "Image.open(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f962a94b-bf13-4154-8973-a9fe8f30e7c3",
   "metadata": {},
   "source": [
    "Additionally, the data you will be using comes from mscoco. However, you can also download from [here](https://huggingface.co/datasets/ChristophSchuhmann/MS_COCO_2017_URL_TEXT) which uses the dataset from [here](https://academictorrents.com/details/74dec1dd21ae4994dfd9069f9cb0443eb960c962). Then use this [link](https://github.com/rom1504/img2dataset) to quickly fill in the datasets files. For the purpose of this notebook you can download a few samples using the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba6c915-3ef8-4433-8628-b85c799a9873",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2. Run distributed training on Amazon SageMaker\n",
    "Next, let's configure the scripts to run on SageMaker training jobs with high performance GPU's. First, you'll need to determine which instances to use. We'd suggest you start with the `ml.g5.12xlarge`, which has 4 GPUs and is known to work nicely with this training script and dataset.\n",
    "\n",
    "The training script we're working with today uses Hugging Face's [`accelerate`](https://huggingface.co/docs/accelerate/index) library to run data parallel on all available GPUs. While likely not as performant on AWS as [SageMaker Distributed Data Parallel](https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel.html), it's still an easy and efficient way to run data parallel on SageMaker Training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f05777-e2a5-480d-a16f-56e95500320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processes_per_host(instance_type):\n",
    "    if instance_type in ['ml.g5.12xlarge', 'ml.g5.24xlarge', 'ml.p3.8xlarge']:\n",
    "        processes_per_host = 4\n",
    "        \n",
    "        \n",
    "    elif instance_type in ['ml.g5.48xlarge', 'ml.p3.16xlarge', 'ml.p3dn.24xlarge', 'ml.p4d.24xlarge']:\n",
    "        processes_per_host = 8\n",
    "        \n",
    "    elif instance_type == 'ml.g4dn.12xlarge':\n",
    "        print ('Stable diffusion is known to not run nicely on the g4dn.12xlarge, recommend a reset to g5.12xlarge')\n",
    "    \n",
    "    else:\n",
    "        print ('Please look up the number of GPUs per node from the EC2 page here: https://aws.amazon.com/ec2/instance-types/ ')\n",
    "    \n",
    "    return processes_per_host\n",
    "\n",
    "\n",
    "instance_type = 'ml.g5.12xlarge'\n",
    "\n",
    "processes_per_host = get_processes_per_host(instance_type)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a0e7a5-66e1-4aad-86dd-9f60ef3ba859",
   "metadata": {},
   "source": [
    "#### Define a profiler configuration to evaluate the performance of the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a6baa-49f1-49f1-b09f-4e46f99291ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import ProfilerConfig, FrameworkProfile\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500, framework_profile_params=FrameworkProfile(num_steps=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d891ac0-9405-4216-a44b-e82844f12994",
   "metadata": {},
   "source": [
    "#### Point to an AWS-managed Deep Learning Container\n",
    "At AWS we provide 70+ prebuilt containers that are battle-tested, and known to run efficiently across SageMaker instances and features.\n",
    "\n",
    "Available images are listed here: https://github.com/aws/deep-learning-containers/blob/master/available_images.md \n",
    "\n",
    "You're welcome to bring your own Dockerfile, and either extend an AWS Deep Learning Container, or simply add the [sagemaker-training toolkit](https://github.com/aws/sagemaker-training-toolkit) to enable remote training job features like script-mode, local mode, distributed training, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dad137b-85f9-4d27-a099-73b1937bcb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.12.1-gpu-py38-cu113-ubuntu20.04-sagemaker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67f57b0-3355-4098-8d81-db9fcabba232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "def get_estimator(instance_type, processes_per_host):\n",
    "    \n",
    "    sess = sagemaker.Session()\n",
    "\n",
    "    role = sagemaker.get_execution_role()\n",
    "\n",
    "    est = HuggingFace(entry_point='finetune.py',\n",
    "                      source_dir='src',\n",
    "                      image_uri=image_uri,\n",
    "                      sagemaker_session=sess,\n",
    "                      role=role,\n",
    "                      instance_type=instance_type,\n",
    "                      keep_alive_time_in_seconds = 3600,\n",
    "                      # output_path = can define s3 output here,\n",
    "                      py_version='py38',\n",
    "                      base_job_name='stable-diffusion', \n",
    "                      instance_count=1,\n",
    "                      # all opt/ml paths point to SageMaker training \n",
    "                      hyperparameters={\n",
    "                        'pretrained_model_name_or_path':'/opt/ml/input/data/training/sd-base-model',\n",
    "                        'dataset_name':'/opt/ml/input/data/training/dataset.parquet',\n",
    "                        'caption_column':'caption',\n",
    "                        'image_column':'sm_key',\n",
    "                        'resolution':256,\n",
    "                        'mixed_precision':'fp16',\n",
    "                        'train_batch_size':2,\n",
    "                        'learning_rate': '1e-10',\n",
    "                        'max_train_steps':100,\n",
    "                        'num_train_epochs':1,\n",
    "                        'output_dir':'/opt/ml/model/sd-output-final',   \n",
    "                      },    \n",
    "                      distribution={\"mpi\":{\"enabled\":True,\"processes_per_host\":processes_per_host}},\n",
    "                      profiler_config=profiler_config\n",
    "    )\n",
    "    \n",
    "    return est\n",
    "\n",
    "est = get_estimator(instance_type, processes_per_host)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d860818-aaf2-48a3-b8c6-c29596631c33",
   "metadata": {},
   "source": [
    "#### Enable FastFile Mode to speed up your training job\n",
    "[`FastFile`](https://aws.amazon.com/about-aws/whats-new/2021/10/amazon-sagemaker-fast-file-mode/) is an option to stream data to your training job, rather than copying from S3. It's great when you don't have more than one million files, but see a bottleneck in the start of your training job. The alternatives are copying from S3, which is slow, or [FSx for Lustre](https://aws.amazon.com/blogs/machine-learning/speed-up-training-on-amazon-sagemaker-using-amazon-efs-or-amazon-fsx-for-lustre-file-systems/), which is the recommend path for very large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95720591-f022-4887-a00a-ec04c0eeccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker.inputs.TrainingInput(s3_train_channel, s3_data_type='S3Prefix', input_mode='FastFile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad1bc59-94c2-4da5-bf86-2db36acd1985",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please note training can take upwards of 25 minutes (13 minutes for saving the model). \n",
    "# only run this cell ONCE!\n",
    "est.fit(inputs=inputs, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026c83a4-fbdb-4e69-8270-a3fa0aff428d",
   "metadata": {},
   "source": [
    "#### Retry on alternate instance types\n",
    "If your job is NOT able to run, due to any of the instances not being available at this precise moment, please retry with alternate instnances. Please note that GPU availability continues to be challenging worldwide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a655170-89ee-48ea-93ff-dbec84a0543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance_type in ['ml.g5.24xlarge', 'ml.g5.48xlarge', 'ml.p3.8xalrge', 'ml.p3.16xlarge', 'ml.p3dn.24xlarge', 'ml.p4d.24xlarge']:\n",
    "    \n",
    "    num_gpus = get_processes_per_host(instance_type)\n",
    "    \n",
    "    est = get_estimator(instance_type, num_gpus)\n",
    "    \n",
    "    try:\n",
    "        est.fit(inputs=inputs, wait=False)\n",
    "        # exit loop if the estimator calls .fit() successfully\n",
    "        break\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bf68d0-4c25-45c0-a4a5-3326cc939f07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(est.model_data) #In case you have to restart kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff323bc-ecd7-4ef2-b3a3-8b9f704119e2",
   "metadata": {},
   "source": [
    "### Step 4. View Profiler Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677b941c-095c-466c-8aa0-494e0ac985f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# paste your SageMaker Training job name and attach to an estimator if you need to restart your kernel\n",
    "#job_name = ''\n",
    "\n",
    "#est = HuggingFace.attach(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0875bb16-0a1e-499e-a351-0ed3bcc3f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# point to rule output in S3\n",
    "rule_output_path = est.output_path + est.latest_training_job.job_name + \"/rule-output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abee8b8-ec3f-410d-a613-8880fb71c0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use the AWS CLI to copy the report locally\n",
    "! aws s3 cp {rule_output_path} ./ --recursive "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588a16fe-59bc-4564-b346-273fe662a9df",
   "metadata": {},
   "source": [
    "#### Steps to Open Profiler Report:\n",
    "1. Open the left-hand side tab\n",
    "2. Click on `ProfilerReport`\n",
    "3. Click on `profiler-output`\n",
    "4. Click on `profiler-report.html`\n",
    "5. Click on the top left-hand side `Trust HTML`.\n",
    "6. Refresh the page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e099d-c6e0-463c-8310-e70576af5651",
   "metadata": {},
   "source": [
    "### Step 5. Distributed Inference\n",
    "Next, we'll point to the model we just trained in the previous step and use it to spin up a SageMaker endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff47324-ae2c-4b72-a022-7afdddd8d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if you need to manually point to your model artifact\n",
    "model_data = 's3://sagemaker-us-east-1-220691188711/stable-diffusion-2022-10-12-16-01-42-682/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c027e-a551-4a63-b9d6-6e6aecdac60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "image_uri = '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.12.1-gpu-py38-cu113-ubuntu20.04-sagemaker'\n",
    "\n",
    "est=HuggingFaceModel(role=role,\n",
    "                     py_version='py38',\n",
    "                     model_data=model_data,\n",
    "                     image_uri=image_uri,\n",
    "                     sagemaker_session= sess,\n",
    "                     # set this to the number of GPUs in the intance type you'd like to use\n",
    "                     model_server_workers= 4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacc9aad-3cac-450b-b3f1-f349425b5e2e",
   "metadata": {},
   "source": [
    "Deploy your model for inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc523a5c-a6ea-4471-aac5-b46358781ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = est.deploy(instance_type='ml.g5.12xlarge',\n",
    "                  initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5c6e1e-d072-441f-8643-fda77ee09ee2",
   "metadata": {},
   "source": [
    "Provide prompts for training. The first text argument is based on this current dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df953476-7ea4-49a7-9d2b-056125cbb0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [caption,'A photo of an astronaut riding a horse on mars', \n",
    "           'A dragonfruit wearing karate belt in the snow.', \n",
    "           'Teddy bear swimming at the Olympics 400m Butter-fly event.',\n",
    "           'A cute sloth holding a small glowing treasure chest.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ef67e8-6054-474d-97ab-fb280ff3874c",
   "metadata": {},
   "source": [
    "For more parameters feel free to explore [here](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion), just add 'parameters':{'key':'value'} to the input dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e555b6-abae-4938-bef8-4cef75b61bb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = [pred.predict({'inputs':prompt}) \\\n",
    "           for prompt in prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf1d934-5d93-4527-be55-e69a0eebe62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [output['images'][0] for output in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b33055-9f20-461d-ac6f-cb8d5db72f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_result(out):\n",
    "    from PIL import Image\n",
    "    from io import BytesIO\n",
    "    import base64\n",
    "    return Image.open(BytesIO(base64.b64decode(out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5fbaf8-033f-4ac2-82d5-69f672e182f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [[process_result(output),prompt] for output,prompt in zip(outputs,prompts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc44f86-2a55-4e50-8045-b53775746c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the results from the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20428b6-19dc-4aca-931d-a4f7d0460722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(images)):\n",
    "    plt.figure()\n",
    "    plt.title(images[i][1])\n",
    "    plt.imshow(images[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e29c9c1-137a-4246-88bc-0d2e63ede648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up your endpoint\n",
    "# pred.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60bd07f-8fbd-4a11-9ce8-810ac1a3d906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.10-cpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
